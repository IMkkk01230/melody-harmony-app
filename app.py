import io
import os
from pathlib import Path
from typing import List, Tuple, Dict

import numpy as np
import pandas as pd
import streamlit as st

# librosa ã¾ã‚ã‚Š
import librosa
import librosa.display
import soundfile as sf  # BytesIO ã« WAV ã‚’æ›¸ããŸã‚


# =============== ãƒšãƒ¼ã‚¸è¨­å®š ==================
st.set_page_config(
    page_title="ãƒ¡ãƒ­ãƒ‡ã‚£ & ãƒãƒ¢ãƒªè§£æã‚¢ãƒ—ãƒª",
    page_icon="ğŸµ",
    layout="centered",
)


# =============== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ===============
@st.cache_data(show_spinner=False)
def _load_audio_from_bytes(data: bytes, sr: int = 22050) -> Tuple[np.ndarray, int]:
    y, sr = librosa.load(io.BytesIO(data), sr=sr, mono=True)
    return y, sr


@st.cache_data(show_spinner=False)
def _load_audio_from_path(path: str, sr: int = 22050) -> Tuple[np.ndarray, int]:
    y, sr = librosa.load(path, sr=sr, mono=True)
    return y, sr


def _estimate_key_from_chroma(chroma: np.ndarray) -> str:
    """å¹³å‡ã‚¯ãƒ­ãƒã‹ã‚‰å¤§é›‘æŠŠã«èª¿æ€§ã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    # ãƒ¡ã‚¸ãƒ£ãƒ¼ / ãƒã‚¤ãƒŠãƒ¼ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç›¸é–¢ã§åˆ¤å®š
    # 12éŸ³ã‚¯ãƒ­ãƒã®ãƒ¡ã‚¸ãƒ£ãƒ¼/ãƒã‚¤ãƒŠãƒ¼ã‚³ãƒ¼ãƒ‰ã®å¹³å‡å½¢ã«è¿‘ã„æ–¹ã‚’æ¡ç”¨
    # ï¼ˆå³å¯†ã§ã¯ãªã„ãŒã€ãƒ‡ãƒ¢ã«ã¯ååˆ†ï¼‰
    major_template = np.array([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1], float)
    minor_template = np.array([1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0], float)

    mean_chroma = chroma.mean(axis=1)
    best = None
    best_score = -1e9
    names = np.array(["C", "C#", "D", "D#", "E", "F",
                      "F#", "G", "G#", "A", "A#", "B"])

    for shift in range(12):
        rot_major = np.roll(major_template, shift)
        rot_minor = np.roll(minor_template, shift)
        s_major = float(np.dot(mean_chroma, rot_major))
        s_minor = float(np.dot(mean_chroma, rot_minor))

        if s_major >= s_minor and s_major > best_score:
            best = f"{names[shift]} major"
            best_score = s_major
        if s_minor > s_major and s_minor > best_score:
            best = f"{names[shift]} minor"
            best_score = s_minor
    return best or "Unknown"


def _chord_name_from_chroma_vector(v: np.ndarray) -> str:
    """1ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã‚¯ãƒ­ãƒãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰ãƒ¡ã‚¸ãƒ£ãƒ¼/ãƒã‚¤ãƒŠãƒ¼ã‚³ãƒ¼ãƒ‰åã‚’ç°¡æ˜“æ¨å®š"""
    names = np.array(["C", "C#", "D", "D#", "E", "F",
                      "F#", "G", "G#", "A", "A#", "B"])

    major_template = np.array([1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1], float)
    minor_template = np.array([1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0], float)

    best = None
    best_score = -1e9
    for shift in range(12):
        s_major = float(np.dot(v, np.roll(major_template, shift)))
        s_minor = float(np.dot(v, np.roll(minor_template, shift)))
        if s_major >= s_minor and s_major > best_score:
            best = f"{names[shift]}"
            suffix = ""
            best_score = s_major
        if s_minor > s_major and s_minor > best_score:
            best = f"{names[shift]}"
            suffix = "m"
            best_score = s_minor
    return (best or "N") + (suffix if best else "")


def _build_chord_timeline(
    y: np.ndarray, sr: int, hop_length: int = 512
) -> Tuple[pd.DataFrame, float, float, str]:
    """
    ãƒ“ãƒ¼ãƒˆã”ã¨ã«ç°¡æ˜“ã‚³ãƒ¼ãƒ‰æ¨å®šã—ã¦ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã«æ•´å½¢ã€‚
    æˆ»ã‚Šå€¤: (DataFrame, æ¨å®šãƒ†ãƒ³ãƒ, ç·æ™‚é–“, æ¨å®šã‚­ãƒ¼)
    """
    duration = len(y) / sr

    # ãƒ†ãƒ³ãƒ/ãƒ“ãƒ¼ãƒˆ
    tempo, beats = librosa.beat.beat_track(y=y, sr=sr, hop_length=hop_length)
    beat_times = librosa.frames_to_time(beats, sr=sr, hop_length=hop_length)
    if len(beat_times) == 0:
        # ãƒ“ãƒ¼ãƒˆãŒå–ã‚Œãªã„å ´åˆã¯ä¸€å®šé–“éš”ã§ä»£æ›¿
        beat_times = np.linspace(0, duration, num=1 + int(duration // 0.5))

    # ã‚¯ãƒ­ãƒï¼ˆCQTï¼‰
    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)
    key_name = _estimate_key_from_chroma(chroma)

    # å„ãƒ“ãƒ¼ãƒˆåŒºé–“ã®å¹³å‡ã‚¯ãƒ­ãƒã‹ã‚‰ã‚³ãƒ¼ãƒ‰æ¨å®š
    frames = np.arange(chroma.shape[1])
    times = librosa.frames_to_time(frames, sr=sr)

    segments: List[Dict] = []
    for i in range(len(beat_times)):
        start = float(beat_times[i])
        end = float(beat_times[i + 1] if i + 1 < len(beat_times) else duration)
        mask = (times >= start) & (times < end)
        if not np.any(mask):
            # ãƒ•ãƒ¬ãƒ¼ãƒ ãªã—åŒºé–“ã¯ã‚¹ã‚­ãƒƒãƒ—
            continue
        mean_v = chroma[:, mask].mean(axis=1)
        name = _chord_name_from_chroma_vector(mean_v)
        dur = max(0.0, end - start)
        label = f"{name} ({dur:.2f}s)"  # â† æ–‡å­—åˆ—é€£çµã¯ã“ã®å½¢ãŒå®‰å…¨
        segments.append(
            {
                "start": start,
                "end": end,
                "dur": dur,
                "chord": name,
                "label": label,
            }
        )

    df = pd.DataFrame(segments)
    if not df.empty:
        df = df[["start", "end", "dur", "chord", "label"]]
    return df, float(tempo), float(duration), key_name


def _mix_harmony(y: np.ndarray, sr: int, shift_semitones: float = 3.0, gain: float = 0.6) -> np.ndarray:
    """
    åŸéŸ³ã«å¯¾ã—ã¦ãƒ”ãƒƒãƒã‚·ãƒ•ãƒˆã—ãŸãƒˆãƒ©ãƒƒã‚¯ã‚’é‡ã­ã‚‹ç°¡æ˜“ãƒãƒ¢ãƒªï¼ˆé•·3åº¦ä¸Šã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã€‚
    """
    harm = librosa.effects.pitch_shift(y, sr=sr, n_steps=shift_semitones)
    # ãƒ¬ãƒ™ãƒ«èª¿æ•´ã—ã¦ãƒŸãƒƒã‚¯ã‚¹
    mix = y + gain * harm
    # ã‚¯ãƒªãƒƒãƒ—é˜²æ­¢
    mx = np.max(np.abs(mix)) + 1e-9
    if mx > 1.0:
        mix = mix / mx
    return mix


def _audio_to_wav_bytes(y: np.ndarray, sr: int) -> bytes:
    """
    ãƒ¡ãƒ¢ãƒªä¸Šï¼ˆBytesIOï¼‰ã« WAV ã§æ›¸ãå‡ºã—ã¦ bytes ã‚’è¿”ã™ã€‚
    """
    bio = io.BytesIO()
    sf.write(bio, y, sr, format="WAV")
    bio.seek(0)
    return bio.getvalue()


# =============== ãƒ¡ã‚¤ãƒ³UI ===============
st.title("ğŸµ ãƒ¡ãƒ­ãƒ‡ã‚£ & ãƒãƒ¢ãƒªè§£æã‚¢ãƒ—ãƒª")

st.caption(
    "MP3/WAV ã‚’è§£æã—ã¦ã€**ãƒ†ãƒ³ãƒãƒ»æ¨å®šã‚­ãƒ¼ãƒ»ç°¡æ˜“ã‚³ãƒ¼ãƒ‰é€²è¡Œ**ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚"
    " ãƒ‡ãƒ¢ã¨ã—ã¦ã€åŸéŸ³ã« 3 åº¦ä¸Šã®ãƒãƒ¢ãƒªã‚’é‡ã­ãŸéŸ³ã‚‚è©¦è´ã§ãã¾ã™ã€‚"
)

with st.expander("åˆ©ç”¨ä¸Šã®æ³¨æ„ï¼ˆè‘—ä½œæ¨©ï¼‰", expanded=False):
    st.markdown(
        "- è‘—ä½œæ¨©ã«é…æ…®ã—ã€**è‡ªåˆ†ã§åˆ©ç”¨å¯èƒ½ãªéŸ³æº**ã®ã¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰/è§£æã—ã¦ãã ã•ã„ã€‚\n"
        "- YouTube ã‹ã‚‰ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã¯å‹•ç”»å´ã®åˆ¶é™ã‚„åœ°åŸŸãƒ»å¹´é½¢åˆ¶é™ã€reCAPTCHA ãªã©ã®ç†ç”±ã§å¤±æ•—ã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚\n"
        "- ã¾ãšã¯ **ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«** ã®è§£æãŒç¢ºå®Ÿã«å‹•ä½œã—ã¾ã™ã€‚"
    )

# å…¥åŠ›æ–¹æ³•
input_mode = st.radio(
    "å…¥åŠ›æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„",
    options=["ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«", "YouTube URL"],
    horizontal=True,
)

audio_bytes: bytes | None = None
audio_name: str = ""

if input_mode == "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«":
    up = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆMP3 / WAVï¼‰", type=["mp3", "wav"])
    if up is not None:
        audio_bytes = up.getvalue()
        audio_name = up.name

else:
    url = st.text_input("YouTube ã® URL ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    agree = st.checkbox("ç§ã¯è‘—ä½œæ¨©ã«æ³¨æ„ã—ã¦åˆ©ç”¨ã—ã¾ã™", value=False)
    if url and agree and st.button("YouTube ã‹ã‚‰éŸ³å£°ã‚’å–å¾—ï¼ˆä»»æ„æ©Ÿèƒ½ï¼‰"):
        with st.spinner("å–å¾—ä¸­...ï¼ˆå¤±æ•—ã™ã‚‹å ´åˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§ãŠè©¦ã—ãã ã•ã„ï¼‰"):
            # ä¾å­˜ã¨ç’°å¢ƒã®éƒ½åˆã§ã€ã“ã“ã§ã¯å®Ÿå‡¦ç†ã‚’çœç•¥ or ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ã€‚
            # å®Ÿè£…ã—ãŸã„å ´åˆã¯ yt_dlp + ffmpeg ã‚’åˆ©ç”¨ã—ã¦ãã ã•ã„ã€‚
            st.warning("ã“ã®ãƒ‡ãƒ¢ã§ã¯ YouTube ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ç„¡åŠ¹åŒ–ã—ã¦ã„ã¾ã™ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚")

# è§£æãƒœã‚¿ãƒ³
if audio_bytes is not None and st.button("éŸ³éš & ãƒãƒ¢ãƒªè§£æé–‹å§‹"):
    try:
        with st.spinner("èª­ã¿è¾¼ã¿ä¸­..."):
            y, sr = _load_audio_from_bytes(audio_bytes, sr=22050)

        with st.spinner("ç‰¹å¾´é‡è§£æä¸­..."):
            df, tempo, duration, key_name = _build_chord_timeline(y, sr)

        # ---- è§£æçµæœã®è¡¨ç¤º ----
        st.subheader("åŸºæœ¬æƒ…å ±")
        c1, c2, c3 = st.columns(3)
        c1.metric("é•·ã•", f"{duration:.2f} s")
        c2.metric("æ¨å®šãƒ†ãƒ³ãƒ", f"{tempo:.1f} BPM")
        c3.metric("æ¨å®šã‚­ãƒ¼", key_name)

        st.subheader("ç°¡æ˜“ã‚³ãƒ¼ãƒ‰é€²è¡Œï¼ˆãƒ“ãƒ¼ãƒˆå˜ä½ï¼‰")
        if df.empty:
            st.info("ã‚³ãƒ¼ãƒ‰ã‚’æ¨å®šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ç„¡éŸ³åŒºé–“ãŒé•·ã„ãƒ»æ¥µç«¯ã«çŸ­ã„éŸ³æºãªã©ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        else:
            st.dataframe(
                df.style.format({"start": "{:.2f}", "end": "{:.2f}", "dur": "{:.2f}"}),
                use_container_width=True,
                height=min(480, 40 + 28 * len(df)),
            )

            # CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            csv = df.to_csv(index=False).encode("utf-8")
            st.download_button(
                "è§£æçµæœï¼ˆCSVï¼‰ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv,
                file_name=(Path(audio_name).stem if audio_name else "analysis") + "_chords.csv",
                mime="text/csv",
            )

        # ---- è©¦è´ï¼šå…ƒéŸ³æº / ç°¡æ˜“ãƒãƒ¢ãƒª ----
        st.subheader("è©¦è´")
        col_a, col_b = st.columns(2)

        with col_a:
            st.caption("åŸéŸ³ï¼ˆãƒ¢ãƒãƒ©ãƒ«ï¼‰")
            st.audio(_audio_to_wav_bytes(y, sr), format="audio/wav")

        with col_b:
            st.caption("ï¼ˆãƒ‡ãƒ¢ï¼‰ææ¡ˆãƒãƒ¢ãƒªã‚’åˆæˆã—ã¦è©¦è´")
            mix = _mix_harmony(y, sr, shift_semitones=3.0, gain=0.6)
            st.audio(_audio_to_wav_bytes(mix, sr), format="audio/wav")

    except Exception as e:
        st.error(f"è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {type(e).__name__}: {e}")

elif audio_bytes is None and input_mode == "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«":
    st.info("MP3 / WAV ã‚’é¸ã‚“ã§ã€ŒéŸ³éš & ãƒãƒ¢ãƒªè§£æé–‹å§‹ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
