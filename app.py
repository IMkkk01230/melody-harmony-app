import os
import tempfile
import subprocess
from typing import List, Tuple

import numpy as np
import pandas as pd
import streamlit as st

# === è§£æç³»ãƒ©ã‚¤ãƒ–ãƒ©ãƒª ===
import librosa
import librosa.display

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="ãƒ¡ãƒ­ãƒ‡ã‚£ï¼†ãƒãƒ¢ãƒªè§£æ", layout="wide")
st.title("ğŸµ ãƒ¡ãƒ­ãƒ‡ã‚£ï¼†ãƒãƒ¢ãƒªè§£æã‚¢ãƒ—ãƒª")

# --------- å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---------
NOTE_NAMES_SHARP = np.array(
    ["C", "C#", "D", "D#", "E", "F", "F#", "G", "G#", "A", "A#", "B"]
)

def hz_to_note_name(hz_array: np.ndarray) -> List[str]:
    """Hz -> éŸ³åï¼ˆC, C#, ...ï¼‰"""
    midi = librosa.hz_to_midi(hz_array, round_=True)
    pcs = (midi % 12).astype(int)
    return NOTE_NAMES_SHARP[pcs].tolist()

def estimate_key_from_chroma(chroma: np.ndarray) -> str:
    """Krumhansl-Schmuckleré¢¨ã®ç°¡æ˜“ã‚­ãƒ¼æ¨å®šï¼ˆãƒ¡ã‚¸ãƒ£ãƒ¼/ãƒã‚¤ãƒŠãƒ¼ï¼‰"""
    # 12æ¬¡å…ƒã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆæ­£è¦åŒ–ï¼‰
    major_profile = np.array(
        [6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88]
    )
    minor_profile = np.array(
        [6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17]
    )
    major_profile = major_profile / major_profile.sum()
    minor_profile = minor_profile / minor_profile.sum()

    avg = chroma.mean(axis=1)  # (12,)
    scores = []
    for shift in range(12):
        major_score = np.dot(np.roll(major_profile, shift), avg)
        minor_score = np.dot(np.roll(minor_profile, shift), avg)
        scores.append(("{} major".format(NOTE_NAMES_SHARP[shift]), major_score))
        scores.append(("{} minor".format(NOTE_NAMES_SHARP[shift]), minor_score))
    key, _ = max(scores, key=lambda x: x[1])
    return key

def chord_templates() -> Tuple[np.ndarray, List[str]]:
    """24ã‚³ãƒ¼ãƒ‰ï¼ˆãƒ¡ã‚¸ãƒ£ãƒ¼/ãƒã‚¤ãƒŠãƒ¼ï¼‰ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ"""
    T = []
    names = []
    triad_major = np.zeros(12); triad_major[[0, 4, 7]] = 1.0    # 1,3,5
    triad_minor = np.zeros(12); triad_minor[[0, 3, 7]] = 1.0    # 1,b3,5
    for i in range(12):
        T.append(np.roll(triad_major, i)); names.append(f"{NOTE_NAMES_SHARP[i]}")
        T.append(np.roll(triad_minor, i)); names.append(f"{NOTE_NAMES_SHARP[i]}m")
    T = np.stack(T, axis=0)  # (24,12)
    # æ­£è¦åŒ–
    T = T / (T.sum(axis=1, keepdims=True) + 1e-9)
    return T, names

def estimate_chords_from_chroma(chroma: np.ndarray, hop_time: float) -> pd.DataFrame:
    """ãƒ•ãƒ¬ãƒ¼ãƒ æ¯ã«æœ€å°¤ã‚³ãƒ¼ãƒ‰ã‚’æ¨å®š â†’ é€£ç¶šåŒºé–“ã‚’ãƒãƒ¼ã‚¸"""
    T, names = chord_templates()  # (24,12)
    # é¡ä¼¼åº¦ï¼šã‚³ã‚µã‚¤ãƒ³ã«è¿‘ã„å†…ç©ãƒ™ãƒ¼ã‚¹
    # chroma shape: (12, frames)
    frames = chroma.shape[1]
    sims = T @ chroma  # (24, frames)
    idx = sims.argmax(axis=0)  # (frames,)
    # é€£ç¶šåŒºé–“ãƒãƒ¼ã‚¸
    segments = []
    start = 0
    for i in range(1, frames):
        if idx[i] != idx[i-1]:
            segments.append((names[idx[start]], start, i-1))
            start = i
    segments.append((names[idx[start]], start, frames-1))
    # DataFrameã¸
    rows = []
    for name, s, e in segments:
        t0 = s * hop_time
        t1 = (e+1) * hop_time
        rows.append({"chord": name, "start_sec": t0, "end_sec": t1, "duration": t1 - t0})
    df = pd.DataFrame(rows)
    return df

def analyze_audio(audio_path: str, limit_sec: float = 90.0):
    """ãƒ¡ã‚¤ãƒ³è§£æï¼šä¸»æ—‹å¾‹ãƒ”ãƒƒãƒãƒ»éŸ³åã€ã‚­ãƒ¼ãƒ»ã‚³ãƒ¼ãƒ‰æ¨å®š"""
    y, sr = librosa.load(audio_path, sr=22050, mono=True, duration=limit_sec)

    # --- ãƒ”ãƒƒãƒæ¨å®šï¼ˆpYINâ†’å¤±æ•—æ™‚ã¯piptrackã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ ---
    try:
        f0, voiced_flag, voiced_probs = librosa.pyin(
            y, fmin=librosa.note_to_hz("C2"), fmax=librosa.note_to_hz("C7")
        )
        # ç„¡å£°éŸ³ã‚’NaNâ†’é™¤å¤–
        pitch_hz = f0[~np.isnan(f0)]
        hop_time = librosa.frames_to_time(1, sr=sr, hop_length=512)  # pyinæ—¢å®š
        time_vec = librosa.frames_to_time(np.arange(len(f0)), sr=sr, hop_length=512)
    except Exception:
        S = np.abs(librosa.stft(y, n_fft=2048, hop_length=512))
        freqs = librosa.fft_frequencies(sr=sr, n_fft=2048)
        idx = S.argmax(axis=0)
        pitch_hz = freqs[idx]
        hop_time = librosa.frames_to_time(1, sr=sr, hop_length=512)
        time_vec = librosa.frames_to_time(np.arange(S.shape[1]), sr=sr, hop_length=512)

    # éŸ³åï¼ˆãƒˆãƒƒãƒ—10ï¼‰
    note_names = hz_to_note_name(pitch_hz)
    top_notes = (
        pd.Series(note_names)
        .value_counts()
        .reset_index()
        .rename(columns={"index": "note", 0: "count"})
        .head(10)
    )

    # --- å’Œå£°ï¼ˆã‚³ãƒ¼ãƒ‰ï¼‰æ¨å®š ---
    chroma = librosa.feature.chroma_cqt(y=y, sr=sr)  # (12, frames)
    key = estimate_key_from_chroma(chroma)
    chord_df = estimate_chords_from_chroma(chroma, hop_time=librosa.frames_to_time(1, sr=sr, hop_length=512))

    return {
        "sr": sr,
        "time_vec": time_vec,
        "pitch_hz": pitch_hz,
        "top_notes": top_notes,
        "key": key,
        "chords": chord_df,
    }

# --------- å…¥åŠ›UI ---------
mode = st.radio("å…¥åŠ›æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„", ["ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«", "YouTube URL"], horizontal=True)
temp_dir = tempfile.mkdtemp()
audio_path = None

if mode == "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«":
    up = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (mp3 / wav, æ¨å¥¨ã¯30ã€œ90ç§’)", type=["mp3", "wav"])
    if up is not None:
        audio_path = os.path.join(temp_dir, up.name)
        with open(audio_path, "wb") as f:
            f.write(up.getbuffer())
        st.success("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº† âœ…")

else:
    yt_url = st.text_input("YouTubeã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå…¬é–‹ãƒ»ãƒ­ã‚°ã‚¤ãƒ³ä¸è¦ã®å‹•ç”»ã‚’æ¨å¥¨ï¼‰")
    consent = st.checkbox("ç§ã¯è‘—ä½œæ¨©ã«æ³¨æ„ã—ã¦åˆ©ç”¨ã—ã¾ã™")
    if st.button("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹"):
        if yt_url.startswith("http") and consent:
            try:
                # å…ˆé ­ã€œ60ç§’ã®ã¿éŸ³å£°æŠ½å‡ºï¼ˆmp3 or wavï¼‰
                import yt_dlp
                ydl_opts = {
                    "format": "bestaudio/best",
                    "outtmpl": os.path.join(temp_dir, "yt_audio.%(ext)s"),
                    "download_ranges": {"download_ranges": ["00:00-00:59"]},
                    "postprocessors": [{
                        "key": "FFmpegExtractAudio",
                        "preferredcodec": "mp3",
                        "preferredquality": "192",
                    }],
                    # åœ°åŸŸåˆ¶é™ã®è»½æ¸›
                    "geo_bypass": True,
                    "nocheckcertificate": True,
                }
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    ydl.download([yt_url])

                # mp3/wavã‚’æ¢ã™
                for f in os.listdir(temp_dir):
                    if f.endswith(".mp3") or f.endswith(".wav"):
                        audio_path = os.path.join(temp_dir, f)
                        break
                if audio_path:
                    st.success("YouTubeéŸ³å£°å–å¾—å®Œäº† âœ…")
                else:
                    st.error("éŸ³å£°å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚åˆ¥ã®URLã§ãŠè©¦ã—ãã ã•ã„ã€‚")
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.warning("æ­£ã—ã„URLã¨åŒæ„ãƒã‚§ãƒƒã‚¯ãŒå¿…è¦ã§ã™ã€‚")

# --------- è§£æå®Ÿè¡Œ ---------
if audio_path:
    st.audio(audio_path)
    if st.button("éŸ³éšï¼†ãƒãƒ¢ãƒªè§£æé–‹å§‹"):
        with st.spinner("è§£æä¸­â€¦ï¼ˆæœ€å¤§90ç§’åˆ†ã‚’å‡¦ç†ï¼‰"):
            result = analyze_audio(audio_path, limit_sec=90.0)

        col1, col2 = st.columns([1,1])

        # ã‚­ãƒ¼ã¨ãƒˆãƒƒãƒ—ãƒãƒ¼ãƒˆ
        with col1:
            st.subheader("æ¨å®šã‚­ãƒ¼ï¼ˆèª¿ï¼‰")
            st.success(result["key"])

            st.subheader("é »å‡ºãƒãƒ¼ãƒˆ Top 10")
            st.dataframe(result["top_notes"], use_container_width=True)

        # ã‚³ãƒ¼ãƒ‰æ¦‚è¦
        with col2:
            st.subheader("æ¨å®šã‚³ãƒ¼ãƒ‰ä¸Šä½ï¼ˆæ»åœ¨æ™‚é–“ï¼‰")
            top_chords = (
                result["chords"]
                .groupby("chord")["duration"]
                .sum()
                .sort_values(ascending=False)
                .reset_index()
                .head(10)
            )
            st.dataframe(top_chords, use_container_width=True)

        # ãƒ”ãƒƒãƒã®ãƒ©ã‚¤ãƒ³ãƒãƒ£ãƒ¼ãƒˆ
        st.subheader("ä¸»æ—‹å¾‹ãƒ”ãƒƒãƒï¼ˆHzï¼‰")
        # NaNã‚’é™¤å»ã—ã¦å¯è¦–åŒ–
        pitch_df = pd.DataFrame({
            "time_sec": result["time_vec"][:len(result["pitch_hz"])],
            "pitch_hz": result["pitch_hz"]
        })
        pitch_df = pitch_df.replace([np.inf, -np.inf], np.nan).dropna()
        st.line_chart(pitch_df.set_index("time_sec"))

        # ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
        st.subheader("ã‚³ãƒ¼ãƒ‰é€²è¡Œã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³")
        # 10ç§’ä»¥ä¸Šç¶šãã‚³ãƒ¼ãƒ‰ã®ã¿å¼·èª¿ï¼ˆãƒã‚¤ã‚ºæŠ‘åˆ¶ï¼‰
        tl = result["chords"].copy()
       tl["label"] = tl["chord"] + "  (" + tl["dur]()

