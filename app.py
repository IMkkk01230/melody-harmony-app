# app.py
# -*- coding: utf-8 -*-
# ãƒ¡ãƒ­ãƒ‡ã‚£ï¼†ãƒãƒ¢ãƒªè§£æžã‚¢ãƒ—ãƒªï¼ˆYouTube / ãƒ­ãƒ¼ã‚«ãƒ«å¯¾å¿œï¼‰
# ä¾å­˜: streamlit, numpy, pandas, librosa, soundfile, matplotlib, yt_dlp, scipy

import os
import io
import sys
import json
import math
import time
import shutil
import warnings
from dataclasses import dataclass
from typing import List, Dict, Optional, Tuple

import numpy as np
import pandas as pd
import streamlit as st
import soundfile as sf
import librosa
import librosa.display
import matplotlib.pyplot as plt
from scipy.signal import medfilt

# YouTube ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
try:
    from yt_dlp import YoutubeDL
    _YTDLP_AVAILABLE = True
except Exception:
    _YTDLP_AVAILABLE = False

warnings.filterwarnings("ignore")

######################################################################
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
######################################################################

TMP_DIR = "tmp_inputs"
os.makedirs(TMP_DIR, exist_ok=True)

def human_time(sec: float) -> str:
    if sec is None or np.isnan(sec):
        return "-"
    m = int(sec // 60)
    s = sec - 60 * m
    return f"{m:02d}:{s:05.2f}"

def save_bytes_to_wav(b: bytes, path: str, sr=44100):
    y, sr0 = sf.read(io.BytesIO(b), dtype="float32", always_2d=False)
    if sr0 != sr:
        y = librosa.resample(y, orig_sr=sr0, target_sr=sr)
    sf.write(path, y, sr)

def normalize_audio(y, peak=0.98):
    m = np.max(np.abs(y)) + 1e-9
    return y * (peak / m)

######################################################################
# YouTube ã‹ã‚‰éŸ³å£°æŠ½å‡º
######################################################################

def download_youtube_audio(url: str, out_dir: str = TMP_DIR, sr=44100) -> Tuple[Optional[str], Optional[str]]:
    """
    Returns: (wav_path, err_message)
    """
    if not _YTDLP_AVAILABLE:
        return None, "yt_dlp ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§ãŠè©¦ã—ãã ã•ã„ã€‚"

    os.makedirs(out_dir, exist_ok=True)
    wav_path = os.path.join(out_dir, "yt_audio.wav")

    # ä¸€æ—¦ã¯ m4a/opus ç­‰ã§è½ã¨ã—ã€ffmpeg ã§ wav åŒ–ï¼ˆStreamlit Cloud ã§ã‚‚å‹•ãï¼‰
    ydl_opts = {
        "format": "bestaudio/best",
        "outtmpl": os.path.join(out_dir, "audio.%(ext)s"),
        "noplaylist": True,
        "quiet": True,
        "nocheckcertificate": True,
        "retries": 2,
        "geo_bypass": True,
        "postprocessors": [{
            "key": "FFmpegExtractAudio",
            "preferredcodec": "wav",
            "preferredquality": "0"
        }],
        "postprocessor_args": [
            "-ar", str(sr),
            "-ac", "1"
        ],
    }

    try:
        with YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])
        # å‡ºåŠ›ã¯ audio.wav ã®ã¯ãš
        cand = os.path.join(out_dir, "audio.wav")
        if not os.path.exists(cand):
            return None, "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆbotå¯¾ç­–ãƒ»å¹´é½¢åˆ¶é™ãƒ»åœ°åŸŸåˆ¶é™ãªã©ã®å¯èƒ½æ€§ï¼‰ã€‚ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§ãŠè©¦ã—ãã ã•ã„ã€‚"
        # çµ±ä¸€åã«
        shutil.move(cand, wav_path)
        return wav_path, None
    except Exception as e:
        return None, f"YouTube ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ã‚¨ãƒ©ãƒ¼: {e}"

######################################################################
# ãƒ¡ãƒ­ãƒ‡ã‚£æŽ¨å®šï¼ˆpyinï¼‰
######################################################################

@dataclass
class MelodyResult:
    times: np.ndarray
    f0_hz: np.ndarray           # NaN ã‚’å«ã‚€
    confidence: np.ndarray      # 0..1

def estimate_melody(y: np.ndarray, sr: int) -> MelodyResult:
    # ä½ŽåŸŸãƒŽã‚¤ã‚ºå¯¾ç­–ã§è»½ãHPF
    y = librosa.effects.preemphasis(y)
    fmin = librosa.note_to_hz("C2")
    fmax = librosa.note_to_hz("C7")

    f0, vflag, _ = librosa.pyin(y, fmin=fmin, fmax=fmax, sr=sr, frame_length=2048, hop_length=256)
    times = librosa.frames_to_time(np.arange(len(f0)), sr=sr, hop_length=256)
    conf = vflag.astype(float)
    return MelodyResult(times=times, f0_hz=f0, confidence=conf)

def f0_to_midi(f0_hz: np.ndarray) -> np.ndarray:
    midi = librosa.hz_to_midi(f0_hz)
    return midi

######################################################################
# ç°¡æ˜“ã‚³ãƒ¼ãƒ‰æŽ¨å®šï¼ˆCQT + ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒžãƒƒãƒãƒ³ã‚°ï¼‰
######################################################################

CHORD_TEMPLATES = {
    # 12 åŠéŸ³ï¼ˆC=0ï¼‰ãƒ™ãƒ¼ã‚¹ã®ãƒ†ãƒ³ãƒ—ãƒ¬
    "C":      [1,0,0,0,1,0,0,1,0,0,0,0],
    "Cm":     [1,0,0,1,0,0,0,1,0,0,0,0],
    "C#":     [0,1,0,0,0,1,0,0,1,0,0,0],
    "C#m":    [0,1,0,0,1,0,0,0,1,0,0,0],
    "D":      [0,0,1,0,0,0,1,0,0,1,0,0],
    "Dm":     [0,0,1,0,0,1,0,0,0,1,0,0],
    "Eb":     [0,0,0,1,0,0,0,1,0,0,1,0],
    "Ebm":    [0,0,0,1,0,0,1,0,0,0,1,0],
    "E":      [0,0,0,0,1,0,0,0,1,0,0,1],
    "Em":     [0,0,0,0,1,0,0,1,0,0,0,1],
    "F":      [1,0,0,0,0,1,0,0,0,1,0,0],  # F A C
    "Fm":     [1,0,0,0,0,1,0,0,1,0,0,0],  # F Ab C
    "F#":     [0,1,0,0,0,0,1,0,0,0,1,0],
    "F#m":    [0,1,0,0,0,0,1,0,0,1,0,0],
    "G":      [0,0,1,0,0,0,0,1,0,0,0,1],
    "Gm":     [0,0,1,0,0,0,0,1,0,0,1,0],
    "Ab":     [1,0,0,1,0,0,0,0,1,0,0,0],
    "Abm":    [1,0,0,1,0,0,0,0,0,1,0,0],
    "A":      [0,1,0,0,1,0,0,0,0,1,0,0],
    "Am":     [0,1,0,0,1,0,0,0,1,0,0,0],
    "Bb":     [0,0,1,0,0,1,0,0,0,0,1,0],
    "Bbm":    [0,0,1,0,0,1,0,0,1,0,0,0],
    "B":      [0,0,0,1,0,0,1,0,0,0,0,1],
    "Bm":     [0,0,0,1,0,0,1,0,0,0,1,0],
}

def est_chords(y: np.ndarray, sr: int, hop_length=4096) -> List[Dict]:
    """
    éžå¸¸ã«ç°¡æ˜“ãªã‚³ãƒ¼ãƒ‰æŽ¨å®šï¼šCQT â†’ 12å¹³å‡ã«ç•³ã¿ â†’ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé¡žä¼¼åº¦æœ€å¤§ã®ã‚³ãƒ¼ãƒ‰ã€‚
    æˆ»ã‚Šå€¤: [{"start":sec, "end":sec, "chord":str, "dur":float}, ...]
    """
    C = np.abs(librosa.cqt(y, sr=sr, hop_length=hop_length, fmin=librosa.note_to_hz("C1"), n_bins=84, bins_per_octave=12))
    chroma = librosa.feature.chroma_cqt(C=C, sr=sr, hop_length=hop_length)
    # æ™‚é–“æ–¹å‘ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ã§å¹³æ»‘
    chroma = medfilt(chroma, kernel_size=(1, 9))

    times = librosa.frames_to_time(np.arange(chroma.shape[1]), sr=sr, hop_length=hop_length)
    temps = {k: np.array(v, dtype=float) for k, v in CHORD_TEMPLATES.items()}
    for k in temps:
        temps[k] /= np.linalg.norm(temps[k]) + 1e-9

    indices = []
    for t in range(chroma.shape[1]):
        v = chroma[:, t]
        v = v / (np.linalg.norm(v) + 1e-9)
        sims = {k: float(v @ temps[k]) for k in temps}
        best = max(sims.items(), key=lambda x: x[1])[0]
        indices.append(best)

    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–
    segs = []
    if len(indices) == 0:
        return segs

    cur = indices[0]
    start = 0
    for i in range(1, len(indices)):
        if indices[i] != cur:
            segs.append({"start": float(times[start]), "end": float(times[i]), "chord": cur})
            cur = indices[i]
            start = i
    segs.append({"start": float(times[start]), "end": float(times[-1] if len(times) > 1 else 0.0), "chord": cur})

    # dur ä»˜ä¸Ž
    for seg in segs:
        seg["dur"] = seg["end"] - seg["start"]
    return segs

######################################################################
# ãƒãƒ¢ãƒªç”Ÿæˆï¼ˆ3rd / 6th ã®å˜ç´”ææ¡ˆï¼‰
######################################################################

def suggest_harmony(midi_seq: np.ndarray, offset_semitone: int) -> np.ndarray:
    """ midi_seq: NaN å«ã‚€ã€‚NaN ã¯ãã®ã¾ã¾ NaN """
    harm = midi_seq.copy()
    mask = ~np.isnan(harm)
    harm[mask] = harm[mask] + offset_semitone
    return harm

def midi_to_note_name(m: float) -> str:
    if np.isnan(m):
        return ""
    n = int(round(m))
    return librosa.midi_to_note(n)

######################################################################
# è¡¨ç¤ºãƒ©ãƒ™ãƒ«ï¼ˆã“ã“ãŒä»¥å‰ã‚¨ãƒ©ãƒ¼ã ã£ãŸæ‰€ã®å®‰å…¨ç‰ˆï¼‰
######################################################################

def _format_label(tl: Dict) -> str:
    chord = str(tl.get("chord", ""))
    # dur ãŒæ•°å€¤ or é–¢æ•°ã®ä¸¡å¯¾å¿œ
    dur_value = None
    if "dur" in tl:
        try:
            dur_value = tl["dur"]() if callable(tl["dur"]) else tl["dur"]
        except Exception:
            dur_value = tl["dur"]

    if dur_value is None or dur_value == "":
        return chord
    try:
        dur_str = f"{float(dur_value):.2f}s"
    except Exception:
        dur_str = str(dur_value)
    return f"{chord} ({dur_str})"

######################################################################
# Streamlit UI
######################################################################

st.set_page_config(page_title="ãƒ¡ãƒ­ãƒ‡ã‚£ï¼†ãƒãƒ¢ãƒªè§£æžã‚¢ãƒ—ãƒª", layout="wide")
st.title("ðŸŽµ ãƒ¡ãƒ­ãƒ‡ã‚£ï¼†ãƒãƒ¢ãƒªè§£æžã‚¢ãƒ—ãƒª")

with st.sidebar:
    st.markdown("**ä½¿ã„æ–¹**")
    st.write("- ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆmp3/wavï¼‰ã¾ãŸã¯ YouTube URL ã‚’é¸æŠž")
    st.write("- è§£æžé–‹å§‹ã‚’æŠ¼ã™ã¨ã€ãƒ¡ãƒ­ãƒ‡ã‚£æŽ¨å®šãƒ»ã‚³ãƒ¼ãƒ‰æŽ¨å®šãƒ»ãƒãƒ¢ãƒªææ¡ˆã‚’è¡Œã„ã¾ã™")
    st.caption("â€» è‘—ä½œæ¨©ã«é…æ…®ã—ã€ç§çš„åˆ©ç”¨ãƒ»ç ”ç©¶ç›®çš„ã®ã¿ã«ã”åˆ©ç”¨ãã ã•ã„")

# å…¥åŠ›åˆ‡ã‚Šæ›¿ãˆ
mode = st.radio("å…¥åŠ›æ–¹æ³•ã‚’é¸æŠžã—ã¦ãã ã•ã„", ["ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«", "YouTube URL"], index=0)
uploaded = None
wav_path = None

col_in1, col_in2 = st.columns([3, 2])
with col_in1:
    if mode == "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«":
        uploaded = st.file_uploader("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (mp3 / wav / m4a ãªã©)", type=["mp3", "wav", "m4a", "aac", "flac"])
    else:
        yt_url = st.text_input("YouTubeã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", placeholder="https://www.youtube.com/watch?v=......")
with col_in2:
    agree = st.checkbox("ç§ã¯è‘—ä½œæ¨©ã«æ³¨æ„ã—ã¦åˆ©ç”¨ã—ã¾ã™", value=True, help="ç§çš„åˆ©ç”¨ã®ç¯„å›²ã§ã”åˆ©ç”¨ãã ã•ã„ã€‚")

btn = st.button("è§£æžé–‹å§‹", type="primary", use_container_width=True)

if btn:
    if not agree:
        st.error("ã”åˆ©ç”¨å‰ã«è‘—ä½œæ¨©ã¸ã®åŒæ„ãŒå¿…è¦ã§ã™ã€‚")
        st.stop()

    # ---- éŸ³å£°å–å¾— ----
    st.info("ðŸ”Š éŸ³å£°ã‚’æº–å‚™ã—ã¦ã„ã¾ã™...")
    sr = 44100
    if mode == "ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«":
        if uploaded is None:
            st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠžã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        wav_path = os.path.join(TMP_DIR, "input.wav")
        try:
            data = uploaded.read()
            save_bytes_to_wav(data, wav_path, sr=sr)
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")
            st.stop()
    else:
        if not yt_url.strip():
            st.error("YouTube ã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            st.stop()
        path, err = download_youtube_audio(yt_url.strip(), out_dir=TMP_DIR, sr=sr)
        if err:
            st.error(err)
            st.stop()
        wav_path = path

    # ---- éŸ³å£°ãƒ­ãƒ¼ãƒ‰ ----
    try:
        y, sr = librosa.load(wav_path, sr=sr, mono=True)
        y = normalize_audio(y)
        duration = len(y) / sr
    except Exception as e:
        st.error(f"éŸ³å£°ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
        st.stop()

    st.success(f"éŸ³å£°æº–å‚™OKï¼ˆ{duration:.2f} ç§’ï¼‰")

    # ---- ãƒ¡ãƒ­ãƒ‡ã‚£æŽ¨å®š ----
    with st.spinner("ðŸŽ¼ ãƒ¡ãƒ­ãƒ‡ã‚£ï¼ˆåŸºæœ¬å‘¨æ³¢æ•°ï¼‰ã‚’æŽ¨å®šä¸­..."):
        mel = estimate_melody(y, sr)
    st.success("ãƒ¡ãƒ­ãƒ‡ã‚£æŽ¨å®šå®Œäº†")

    # ---- ã‚³ãƒ¼ãƒ‰æŽ¨å®š ----
    with st.spinner("ðŸŽ¹ ã‚³ãƒ¼ãƒ‰ï¼ˆç°¡æ˜“ï¼‰ã‚’æŽ¨å®šä¸­..."):
        chord_tl = est_chords(y, sr)
        for tl in chord_tl:
            tl["label"] = _format_label(tl)  # â˜…ã“ã“ãŒå®‰å…¨ç‰ˆ
    st.success(f"ã‚³ãƒ¼ãƒ‰å€™è£œ: {len(chord_tl)} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")

    # ---- ãƒãƒ¢ãƒªææ¡ˆ ----
    midi = f0_to_midi(mel.f0_hz)
    harm_up3 = suggest_harmony(midi, +3)   # é•·çŸ­ã¯æ°—ã«ã›ãš 3åŠéŸ³
    harm_down3 = suggest_harmony(midi, -3)
    harm_up4 = suggest_harmony(midi, +4)
    harm_down5 = suggest_harmony(midi, -5)

    # ===== ç”»é¢å‡ºåŠ› =====
    tabs = st.tabs(["æ¦‚è¦", "ãƒ¡ãƒ­ãƒ‡ã‚£å¯è¦–åŒ–", "ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³", "ãƒãƒ¢ãƒªï¼ˆææ¡ˆï¼‰", "ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›"])

    # --- æ¦‚è¦
    with tabs[0]:
        st.subheader("è§£æžæ¦‚è¦")
        c1, c2, c3 = st.columns(3)
        with c1:
            st.metric("å…¨ä½“é•·ã•", f"{duration:.2f} s")
        with c2:
            voiced = np.mean(~np.isnan(mel.f0_hz)) * 100
            st.metric("æœ‰å£°çŽ‡ï¼ˆã–ã£ãã‚Šï¼‰", f"{voiced:.1f} %")
        with c3:
            st.metric("ã‚³ãƒ¼ãƒ‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°", len(chord_tl))

        st.audio(wav_path)

    # --- ãƒ¡ãƒ­ãƒ‡ã‚£å¯è¦–åŒ–
    with tabs[1]:
        st.subheader("ãƒ¡ãƒ­ãƒ‡ã‚£ï¼ˆpyinï¼‰ã®æŽ¨å®šå¯è¦–åŒ–")
        fig, ax = plt.subplots(figsize=(12, 4))
        D = librosa.amplitude_to_db(np.abs(librosa.stft(y, n_fft=1024, hop_length=256)), ref=np.max)
        librosa.display.specshow(D, sr=sr, hop_length=256, x_axis="time", y_axis="hz", cmap="magma", ax=ax)
        ax.plot(mel.times, mel.f0_hz, color="cyan", lw=1.5, label="f0 (pyin)")
        ax.set_ylim(50, 2000)
        ax.legend(loc="upper right")
        ax.set_title("Spectrogram + f0")
        st.pyplot(fig, use_container_width=True)

        # è¡¨ç¤ºç”¨ãƒ†ãƒ¼ãƒ–ãƒ«
        df_mel = pd.DataFrame({
            "time": mel.times,
            "f0_hz": mel.f0_hz,
            "midi": f0_to_midi(mel.f0_hz),
            "note": [midi_to_note_name(v) for v in f0_to_midi(mel.f0_hz)]
        })
        st.dataframe(df_mel.head(500), use_container_width=True, height=300)

    # --- ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³
    with tabs[2]:
        st.subheader("ã‚³ãƒ¼ãƒ‰ï¼ˆç°¡æ˜“ï¼‰ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³")
        if len(chord_tl) == 0:
            st.info("ã‚³ãƒ¼ãƒ‰ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            df_ch = pd.DataFrame(chord_tl)
            df_ch["start(h:m:s)"] = df_ch["start"].apply(human_time)
            df_ch["end(h:m:s)"] = df_ch["end"].apply(human_time)
            st.dataframe(df_ch[["start", "end", "start(h:m:s)", "end(h:m:s)", "chord", "dur", "label"]],
                         use_container_width=True, height=350)

            # ã–ã£ãã‚Šã®æ£’å¯è¦–åŒ–
            fig, ax = plt.subplots(figsize=(12, 2 + 0.2 * len(chord_tl)))
            y0 = 0
            for tl in chord_tl:
                ax.barh(0, tl["dur"], left=tl["start"], height=0.4, color="#4CAF50")
                ax.text(tl["start"] + 0.02, 0, tl["label"], va="center", ha="left", color="white", fontsize=9)
            ax.set_yticks([])
            ax.set_xlabel("Time (s)")
            ax.set_xlim(0, duration + 0.1)
            ax.set_title("Chord Segments")
            st.pyplot(fig, use_container_width=True)

    # --- ãƒãƒ¢ãƒªææ¡ˆ
    with tabs[3]:
        st.subheader("ãƒãƒ¢ãƒªï¼ˆææ¡ˆï¼‰")
        st.caption("â€» ã‚ãã¾ã§æ©Ÿæ¢°çš„ãª3åº¦/4åº¦/5åº¦ã®å˜ç´”ææ¡ˆã§ã™ã€‚å®Ÿæ›²ã§ã¯ä¸å”å’Œã‚„é¿ã‘ãŸã„é€²è¡ŒãŒå‡ºã‚‹ãŸã‚ã€è€³ã§æœ€çµ‚èª¿æ•´ã—ã¦ãã ã•ã„ã€‚")

        choice = st.selectbox("ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒ«", ["+3ï¼ˆä¸Š3åº¦ï¼‰", "-3ï¼ˆä¸‹3åº¦ï¼‰", "+4ï¼ˆä¸Š4åº¦ï¼‰", "-5ï¼ˆä¸‹5åº¦ï¼‰"], index=0)
        map_choice = {"+3ï¼ˆä¸Š3åº¦ï¼‰": harm_up3, "-3ï¼ˆä¸‹3åº¦ï¼‰": harm_down3, "+4ï¼ˆä¸Š4åº¦ï¼‰": harm_up4, "-5ï¼ˆä¸‹5åº¦ï¼‰": harm_down5}
        harm = map_choice[choice]

        df_harm = pd.DataFrame({
            "time": mel.times,
            "mel_note": [midi_to_note_name(v) for v in f0_to_midi(mel.f0_hz)],
            "harm_midi": harm,
            "harm_note": [midi_to_note_name(v) for v in harm]
        })
        st.dataframe(df_harm.head(500), use_container_width=True, height=350)

        # MIDIãƒŽãƒ¼ãƒˆ â†’ å‘¨æ³¢æ•° â†’ ã‚·ãƒ³ã‚»çš„ã«è©¦è´ï¼ˆç°¡æ˜“ã‚µã‚¤ãƒ³æ³¢ï¼‰
        def synth_from_midi(midis: np.ndarray, sr=22050) -> np.ndarray:
            dur = mel.times[-1] if len(mel.times) > 0 else 0.0
            n = int(dur * sr) + sr // 2
            out = np.zeros(n, dtype=np.float32)
            hop = int(round((mel.times[1] - mel.times[0]) * sr)) if len(mel.times) > 1 else 512
            pos = 0
            phase = 0.0
            for i in range(len(midis)):
                length = hop
                if i == len(midis) - 1 and len(mel.times) > 1:
                    length = int(((mel.times[i] + (mel.times[i] - mel.times[i-1])) - mel.times[i]) * sr)
                hz = librosa.midi_to_hz(midis[i]) if not np.isnan(midis[i]) else 0.0
                if hz <= 0:
                    pos += length
                    continue
                t = np.arange(length) / sr
                wave = 0.3 * np.sin(2 * np.pi * hz * t + phase)
                phase = (phase + 2 * np.pi * hz * length / sr) % (2 * np.pi)
                out[pos:pos+length] += wave.astype(np.float32)
                pos += length
            return normalize_audio(out)

      if st.button("ï¼ˆãƒ‡ãƒ¢ï¼‰ææ¡ˆãƒãƒ¢ãƒªã‚’åˆæˆã—ã¦è©¦è´"):
    with st.spinner("ç”Ÿæˆä¸­..."):
        synth = synth_from_midi(harm, sr=22050)
        buf = io.BytesIO()
        sf.write(buf, synth, 22050, format="WAV")
        buf.seek(0)
    st.audio(buf, format="audio/wav")

    # --- ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›
    with tabs[4]:
        st.subheader("ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›")
        # ãƒ¡ãƒ­ãƒ‡ã‚£
        df_mel_out = pd.DataFrame({
            "time": mel.times,
            "f0_hz": mel.f0_hz,
            "midi": f0_to_midi(mel.f0_hz),
            "note": [midi_to_note_name(v) for v in f0_to_midi(mel.f0_hz)]
        })
        csv_mel = df_mel_out.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ãƒ¡ãƒ­ãƒ‡ã‚£CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv_mel, file_name="melody.csv", mime="text/csv")

        # ã‚³ãƒ¼ãƒ‰
        df_ch_out = pd.DataFrame(chord_tl)
        csv_ch = df_ch_out.to_csv(index=False).encode("utf-8-sig")
        st.download_button("ã‚³ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", csv_ch, file_name="chords.csv", mime="text/csv")

        json_all = {
            "duration_sec": float(duration),
            "melody": df_mel_out.to_dict(orient="records"),
            "chords": chord_tl,
        }
        st.download_button("JSONã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", json.dumps(json_all, ensure_ascii=False, indent=2).encode("utf-8"),
                           file_name="analysis.json", mime="application/json")

else:
    st.caption("ã€Œè§£æžé–‹å§‹ã€ã‚’æŠ¼ã™ã¨å‡¦ç†ãŒå§‹ã¾ã‚Šã¾ã™ã€‚YouTube ã§å¤±æ•—ã™ã‚‹å ´åˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã§ãŠè©¦ã—ãã ã•ã„ã€‚")
